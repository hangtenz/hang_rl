{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JndnmDMp66FL"
   },
   "source": [
    "#### Copyright 2017 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "hMqWDc_m6rUC"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-"
   },
   "source": [
    "# First Steps with TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNcnN-NHKGbM"
   },
   "source": [
    "This notebook is modified from `first_steps_with_tensorflow.ipynb` to use Tensorflow 2.x instead of Tensorflow 1.x. We borrow heavily from [@fchollet's Twitter thread]() and recommend everyone to check it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bd2Zkk1LE2Zr"
   },
   "source": [
    "**Learning Objectives:**\n",
    "  * Learn fundamental TensorFlow 2.x concepts\n",
    "  * Create a multi-layer perceptron model in TensorFlow to predict median housing price, at the granularity of city blocks, based on nine numerical features.\n",
    "  * Evaluate the accuracy of a model's predictions using Root Mean Squared Error (RMSE)\n",
    "  * Convert the model to run on static graph for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxiIKhP4E2Zr"
   },
   "source": [
    "The [data](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) is based on 1990 census data from California."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Setup\n",
    "In this first cell, we'll load the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rVFf5asKE2Zt",
    "outputId": "afbc289e-360c-41ce-e174-f661a902a2c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "# #uncomment if you're running from colab\n",
    "# %tensorflow_version 2.x\n",
    "\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "import math\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model\n",
    "print(tf.__version__)\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Next, we'll load our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ivCDWnwE2Zx"
   },
   "outputs": [],
   "source": [
    "cali_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "# cali_df = pd.read_csv('data/california_housing_train.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVk_qlG6U80j"
   },
   "source": [
    "We'll randomize the data, just to be sure not to get any pathological ordering effects that might harm the performance of Stochastic Gradient Descent. Additionally, we'll scale `median_house_value` to be in units of thousands, so it can be learned a little more easily with learning rates in a range that we usually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "r0eVyguIU80m",
    "outputId": "8bd3c415-6b56-4428-fb43-0c2fcee38c1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>-117.99</td>\n",
       "      <td>33.86</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>3.4167</td>\n",
       "      <td>187.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>-118.21</td>\n",
       "      <td>33.82</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1719.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>2.8438</td>\n",
       "      <td>139.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>-120.56</td>\n",
       "      <td>38.48</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3545.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>3.4609</td>\n",
       "      <td>120.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15008</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.47</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>6.1244</td>\n",
       "      <td>308.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>-118.23</td>\n",
       "      <td>33.91</td>\n",
       "      <td>33.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.5893</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "4173     -117.99     33.86                36.0       1138.0           228.0   \n",
       "5993     -118.21     33.82                34.0       1719.0           398.0   \n",
       "10665    -120.56     38.48                14.0       3545.0           702.0   \n",
       "15008    -122.24     37.47                40.0       1504.0           270.0   \n",
       "6148     -118.23     33.91                33.0        677.0           182.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "4173        725.0       219.0         3.4167               187.2  \n",
       "5993       1444.0       372.0         2.8438               139.3  \n",
       "10665       946.0       411.0         3.4609               120.9  \n",
       "15008       689.0       287.0         6.1244               308.8  \n",
       "6148        984.0       174.0         2.5893                88.9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_df = cali_df.reindex(\n",
    "    np.random.permutation(cali_df.index))\n",
    "cali_df[\"median_house_value\"] /= 1000.0\n",
    "cali_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt"
   },
   "source": [
    "## Examine the Data\n",
    "\n",
    "It's a good idea to get to know your data a little bit before you work with it.\n",
    "\n",
    "We'll print out a quick summary of a few useful statistics on each column: count of examples, mean, standard deviation, max, min, and various quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "outputId": "d014a6c5-1473-484f-b93c-fd6966498087"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.562108</td>\n",
       "      <td>35.625225</td>\n",
       "      <td>28.589353</td>\n",
       "      <td>2643.664412</td>\n",
       "      <td>539.410824</td>\n",
       "      <td>1429.573941</td>\n",
       "      <td>501.221941</td>\n",
       "      <td>3.883578</td>\n",
       "      <td>207.300912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.005166</td>\n",
       "      <td>2.137340</td>\n",
       "      <td>12.586937</td>\n",
       "      <td>2179.947071</td>\n",
       "      <td>421.499452</td>\n",
       "      <td>1147.852959</td>\n",
       "      <td>384.520841</td>\n",
       "      <td>1.908157</td>\n",
       "      <td>115.983764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.790000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>790.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>2.566375</td>\n",
       "      <td>119.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.544600</td>\n",
       "      <td>180.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.000000</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3151.250000</td>\n",
       "      <td>648.250000</td>\n",
       "      <td>1721.000000</td>\n",
       "      <td>605.250000</td>\n",
       "      <td>4.767000</td>\n",
       "      <td>265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>37937.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500.001000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  17000.000000  17000.000000        17000.000000  17000.000000   \n",
       "mean    -119.562108     35.625225           28.589353   2643.664412   \n",
       "std        2.005166      2.137340           12.586937   2179.947071   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.790000     33.930000           18.000000   1462.000000   \n",
       "50%     -118.490000     34.250000           29.000000   2127.000000   \n",
       "75%     -118.000000     37.720000           37.000000   3151.250000   \n",
       "max     -114.310000     41.950000           52.000000  37937.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    17000.000000  17000.000000  17000.000000   17000.000000   \n",
       "mean       539.410824   1429.573941    501.221941       3.883578   \n",
       "std        421.499452   1147.852959    384.520841       1.908157   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        297.000000    790.000000    282.000000       2.566375   \n",
       "50%        434.000000   1167.000000    409.000000       3.544600   \n",
       "75%        648.250000   1721.000000    605.250000       4.767000   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        17000.000000  \n",
       "mean           207.300912  \n",
       "std            115.983764  \n",
       "min             14.999000  \n",
       "25%            119.400000  \n",
       "50%            180.400000  \n",
       "75%            265.000000  \n",
       "max            500.001000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep"
   },
   "source": [
    "## Build the First Model\n",
    "\n",
    "In this exercise, we'll try to predict `median_house_value`, which will be our label (sometimes also called a target). We'll use every other numerical features as our input feature.\n",
    "\n",
    "**NOTE:** Our data is at the city block level, so this feature represents the total number of rooms in that block.\n",
    "\n",
    "To train our model, we'll use a multi-layer perceptron (MLP) model based on Tensorflow 2.x `tf.keras` APIs and Eager Mode. We will then convert the model to static graph mode for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cpcsieFhsNI"
   },
   "source": [
    "### Step 1: Define Features and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EL8-9d4ZJNR7"
   },
   "source": [
    "In order to import our training data into TensorFlow, we need to specify what type of data each feature contains. There are two main types of data we'll use in this and future exercises:\n",
    "\n",
    "* **Categorical Data**: Data that is textual. In this exercise, our housing data set does not contain any categorical features, but examples you might see would be the home style, the words in a real-estate ad.\n",
    "\n",
    "* **Numerical Data**: Data that is a number (integer or float) and that you want to treat as a number. As we will discuss more later sometimes you might want to treat numerical data (e.g., a postal code) as if it were categorical.\n",
    "\n",
    "In TensorFlow, we indicate a feature's data type using a construct called a **feature column**. Feature columns store only a description of the feature data; they do not contain the feature data itself.\n",
    "\n",
    "To start, we're going to use just numerical features and median household value as target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rhEbFCZ86cDZ",
    "outputId": "5bc2d1e9-c76d-4f77-8ad2-ff3e3eb70307"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13600, 9), (3400, 9))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income']\n",
    "target = ['median_house_value']\n",
    "\n",
    "#split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(cali_df[num_features+target],test_size=0.2)\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "VbxOn9ZCOekc",
    "outputId": "62a7431c-e51d-40a6-e381-16a7bad89392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.23139175, -0.06974687, -0.1375708 , ...,  1.04125404,\n",
       "         0.13598076,  0.09589534]),\n",
       " array([0.77020998, 0.8725401 , 0.94528348, ..., 1.34513729, 0.5123828 ,\n",
       "        0.84625649]),\n",
       " array([ 0.0928867 , -0.08648356, -0.36888908, ...,  0.15726645,\n",
       "         0.05724429,  0.24894684]),\n",
       " array([0.69313593, 0.87566229, 0.58386844, ..., 0.65015914, 1.03230631,\n",
       "        0.76096879]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(train_df[num_features])\n",
    "train_scaled = scaler.transform(train_df[num_features])\n",
    "valid_scaled = scaler.transform(valid_df[num_features])\n",
    "#print(type(train_scaled))\n",
    "#np.mean(train_scaled)\n",
    "#print(np.mean(train_scaled, axis=1))\n",
    "train_scaled.mean(1), train_scaled.std(1), valid_scaled.mean(1), valid_scaled.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jmmq5X2BNVrb",
    "outputId": "f0c66549-82e5-49f0-af67-148d272d4ea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13600, 8), (13600, 1), (3400, 8), (3400, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to numpy\n",
    "train_x = np.array(train_scaled)\n",
    "train_y = np.array(train_df[target])\n",
    "valid_x = np.array(valid_scaled)\n",
    "valid_y = np.array(valid_df[target])\n",
    "train_x.shape,train_y.shape,valid_x.shape,valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUajUVm8KGbz",
    "outputId": "e8a6ee06-fc6b-4a3a-c942-680ad60e1273"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.23553132, -1.32858046,  0.58833289, -0.51416241, -0.65319214,\n",
       "         -0.65762819, -0.63279288,  0.11135788],\n",
       "        [-1.10163415,  0.60096547, -1.62739982,  0.03328552,  0.50424149,\n",
       "          1.01244559,  0.56940094, -0.54927999],\n",
       "        [ 1.25550709, -1.09441226, -0.91520002, -0.38907102, -0.54318812,\n",
       "         -0.47450993, -0.57767046,  1.63797831],\n",
       "        [ 0.910925  , -0.72910988,  1.85446587, -0.35768278, -0.53362255,\n",
       "         -0.42520886, -0.45430123,  0.18629013],\n",
       "        [ 0.63625812, -0.89771098,  0.58833289,  0.2271541 ,  0.49467592,\n",
       "          0.33895775,  0.51427851, -0.06569767],\n",
       "        [-0.87191276,  1.09271867,  1.85446587,  0.00512842, -0.170131  ,\n",
       "         -0.24032984, -0.01857159, -0.34471965],\n",
       "        [-0.06788789,  0.55413183,  0.27179965, -0.00918093, -0.02664749,\n",
       "          0.12326556, -0.02382134, -0.61145337],\n",
       "        [ 0.6911915 , -0.82277716,  0.74659952,  0.00974434,  0.20770891,\n",
       "          0.17344701,  0.27016492, -0.06930572],\n",
       "        [-0.45741546,  1.88889053,  0.27179965, -0.52016311, -0.59819013,\n",
       "         -0.9912908 , -0.97140206, -1.04651012],\n",
       "        [-0.69712474,  0.95221776, -0.99433333,  1.07002083,  0.86773305,\n",
       "          1.07759344,  0.79514039,  0.20762464]]), array([[171.2],\n",
       "        [162. ],\n",
       "        [267.6],\n",
       "        [140.1],\n",
       "        [300. ],\n",
       "        [107.6],\n",
       "        [ 68. ],\n",
       "        [161.9],\n",
       "        [ 71. ],\n",
       "        [138.3]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:10],train_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4M-rTFHL2UkA"
   },
   "source": [
    "### Step 2: Create `Dataset` Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uH9JJrIKGb3"
   },
   "source": [
    "`Dataset` object is responsible for shuffling and feeding the features-target pairs into the architecture. We also create a validation `Dataset` with batch size equal to all validation examples and no shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uNsy47-1Jxe9",
    "outputId": "fed2f056-b4b5-49b7-f70a-d76c1656dd33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DatasetV1Adapter shapes: ((?, 8), (?, 1)), types: (tf.float64, tf.float64)>,\n",
       " <DatasetV1Adapter shapes: ((?, 8), (?, 1)), types: (tf.float64, tf.float64)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datasets\n",
    "#shuffle with buffer equal to size of dataset\n",
    "#print(train_y)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y)).shuffle(buffer_size=train_y.shape[0]).batch(64)\n",
    "#no shuffling for validation\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y)).batch(valid_y.shape[0])\n",
    "train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2OPpS0SQ4z4"
   },
   "source": [
    "## Step 3: Define Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hSxzvhAyKGb9"
   },
   "source": [
    "There are [several ways](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model) to define an architecture in Tensorflow 2.0. Here we introduce:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4PTWXzyKGb-"
   },
   "source": [
    "#### Step 3.1: Subclassing `tf.keras.layers.Layer` and `tf.keras.Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSEZWZ_uKGb_"
   },
   "source": [
    "You can create your own `tf.keras.layers.Layer` object, which acts as a layer or a collection of layers in your architecture. Here we define our own `Linear` layer for a fully-connect layer instead of using `tf.keras.layers.Dense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CistZoLKGcB"
   },
   "outputs": [],
   "source": [
    "class Linear(layers.Layer):\n",
    "    def __init__(self, output_dim):\n",
    "        #print(output_dim)\n",
    "        super(Linear,self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "    #use build method to build the weights without having to specify input dimension\n",
    "    def build(self,x_shape):\n",
    "        self.w = self.add_weight(shape=(x_shape[-1],self.output_dim),\n",
    "                                initializer='he_normal',trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.output_dim,),\n",
    "                                initializer='zeros',trainable=True)\n",
    "    def call(self,x):\n",
    "        return tf.matmul(x,self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ypzI0s_LQ832"
   },
   "outputs": [],
   "source": [
    "#piece linear layers together to get our simple MLP architecture\n",
    "class MLP(Model):\n",
    "    def __init__(self,output_dims=[32,32,1]):\n",
    "        super(MLP,self).__init__()\n",
    "        #we intentionally do not specify any activation to show we can use functional tf.nn later\n",
    "        self.linears = [Linear(i) for i in output_dims]\n",
    "        #print(self.linears)\n",
    "#       #we can also use the predefined tf.keras.layers.Dense; we can also specify activations\n",
    "        self.linears = [tf.keras.layers.Dense(i,activation='relu') for i in output_dims]\n",
    "    def call(self,x):\n",
    "        #print(\"x = \",x)\n",
    "        for l in self.linears[:-1]:\n",
    "            print(l)\n",
    "            x = tf.nn.relu(l(x))\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDMZqBvvKGcL",
    "outputId": "a0168728-86ac-4c8f-bc2d-7173af617ab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001BF6AA266D8>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001BF6AB6C630>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(1)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MLP([32,32,1])\n",
    "x = tf.random.normal((64,9))\n",
    "#print(x)\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  33        \n",
      "=================================================================\n",
      "Total params: 1,409\n",
      "Trainable params: 1,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#can only see summary after you called build() or passed something\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ov5WYnW7KGcO"
   },
   "source": [
    "#### Step 3.2: Quick and Dirty with `tf.keras.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MX9xzUF0KGcR"
   },
   "source": [
    "`tf.keras.Sequential` will create a model but do not build it unless you specify the input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYpSpy6pKGcS",
    "outputId": "08d57b38-76c0-44de-cfc9-c7e957347d24"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-001bc5aa961f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \"\"\"\n\u001b[0;32m   1503\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1504\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   1505\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "#without input shape\n",
    "m = tf.keras.Sequential()\n",
    "for i in [32,32]:\n",
    "    m.add(tf.keras.layers.Dense(i,activation='relu'))\n",
    "m.add(tf.keras.layers.Dense(1))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-l2y9KPlKGcY",
    "outputId": "8899f7ef-af48-45bf-8ee1-e6543164ffcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                320       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,409\n",
      "Trainable params: 1,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#with input shape\n",
    "m = tf.keras.Sequential()\n",
    "m.add(tf.keras.layers.Dense(32,activation='relu',input_dim=9))\n",
    "m.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "m.add(tf.keras.layers.Dense(1))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.3: Functionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                320       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,409\n",
      "Trainable params: 1,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(9,))\n",
    "x = layers.Dense(32, activation='relu')(inputs)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "m = Model(inputs=inputs, outputs=outputs)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDlaR8HGKGcf"
   },
   "source": [
    "### Step 4: Define Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PDNJsYBKGcg"
   },
   "source": [
    "We need to specify which loss function to optimize for. In our case, we use a simple mean squared error loss (MSE loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUc20G0-KGch",
    "outputId": "7e5d30b0-75c6-49bb-d36e-3055e5de1040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: (10, 1), preds: (10, 1), MSE Loss: 0.5581936836242676\n",
      "MSE Loss by hand: 0.5581936836242676\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "y = tf.ones((10,1))\n",
    "preds = tf.random.uniform((10,1))\n",
    "print(f'y: {y.shape}, preds: {preds.shape}, MSE Loss: {loss_fn(y,preds)}')\n",
    "sess = tf.InteractiveSession()\n",
    "print(f'MSE Loss by hand: {((y.numpy()-preds.numpy())**2).mean()}')\n",
    "#print(f'MSE Loss by hand: {((y-preds)**2).numpy().mean(0)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXSkXbIyKGck"
   },
   "source": [
    "### Step 5: Define Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghwAI7_YKGcl"
   },
   "source": [
    "Last step of preparation is to define which optimizer to apply the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYIgRdC2KGcm"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3,\n",
    "                                    beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IoxWuHWMKGcp"
   },
   "source": [
    "### Step 6: Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ncaQfxQBKGcq"
   },
   "source": [
    "We put what we have prepared so far together: datasets, architecture, loss function, and optimizer to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8z9-sdDeKGcr"
   },
   "outputs": [],
   "source": [
    "#datasets\n",
    "#shuffle with buffer equal to size of dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\\\n",
    "  .shuffle(buffer_size=train_y.shape[0]).batch(64)\n",
    "#no shuffling for validation\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\\\n",
    "  .batch(valid_y.shape[0])\n",
    "train_ds, valid_ds\n",
    "\n",
    "#architecture\n",
    "class MLP(Model):\n",
    "    def __init__(self,output_dims=[64,32,1]):\n",
    "        super(MLP,self).__init__()\n",
    "        #we can also use the predefined tf.keras.layers.Dense; we can also specify activations\n",
    "        self.linears = [layers.Dense(i,activation='relu') for i in output_dims]\n",
    "    def call(self,x):\n",
    "        for l in self.linears[:-1]: x = l(x)\n",
    "        return self.linears[-1](x)\n",
    "m = MLP([32,32,1])\n",
    "\n",
    "#loss fn\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 2e-3,\n",
    "                                    beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygZFHjBVKGcu"
   },
   "source": [
    "As we train the model in Eager Mode, we use `tf.GradientTape()` to record the gradients and use our optimizer to apply them. Let's say we train for 10 epochs (10 rounds of all data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mhuX19P9KGcu",
    "outputId": "ce7fb859-8b2c-41bc-e818-899b817740e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 1 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 2 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 3 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 4 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 5 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 6 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 7 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 8 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "epoch 9 - Train Loss: 62669.19140625;    Valid Loss: 53845.43359375\n",
      "Done in 0:00:18.488117\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "#to log epoch-level train and validation losses\n",
    "epoch_train_losses = []\n",
    "epoch_valid_losses = []\n",
    "for e in range(10):\n",
    "    #training loop\n",
    "    for i,(x,y) in enumerate(train_ds):\n",
    "        epoch_train_loss = []\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = m(x) #prediction\n",
    "            train_loss = loss_fn(y,preds) #record loss\n",
    "            epoch_train_loss.append(train_loss)\n",
    "            #record gradients\n",
    "            gradients = tape.gradient(train_loss,m.trainable_weights)\n",
    "        #update \n",
    "        optimizer.apply_gradients(zip(gradients,m.trainable_weights))\n",
    "    epoch_train_losses.append(np.mean(epoch_train_loss))\n",
    "    \n",
    "    #validation loop\n",
    "    for i,(x,y) in enumerate(valid_ds):\n",
    "        epoch_valid_loss = []\n",
    "        preds = m(x) #prediction\n",
    "        valid_loss = loss_fn(y,preds) #record loss\n",
    "        epoch_valid_loss.append(valid_loss)\n",
    "        # do not record or apply gradients\n",
    "    epoch_valid_losses.append(np.mean(epoch_valid_loss))\n",
    "    \n",
    "    #log\n",
    "    print(f'epoch {e} - Train Loss: {np.mean(epoch_train_loss)};\\\n",
    "    Valid Loss: {np.mean(epoch_valid_loss)}')\n",
    "\n",
    "print(f'Done in {datetime.now()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdQ_fioRKGcx",
    "outputId": "23323062-3fea-4682-a70b-5b8c9313f47b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf6bf9c6d8>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot losses by epoch\n",
    "plt.plot(epoch_train_losses)\n",
    "plt.plot(epoch_valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0IztwdK2f3F"
   },
   "source": [
    "### Step 7: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKWstXXPzOVz"
   },
   "source": [
    "Is this a good model? How would you judge how large this error is?\n",
    "\n",
    "Mean Squared Error (MSE) can be hard to interpret, so we often look at Root Mean Squared Error (RMSE)\n",
    "instead.  A nice property of RMSE is that it can be interpreted on the same scale as the original targets.\n",
    "\n",
    "Let's compare the RMSE to the difference of the min and max of our targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UwqGbbxP53O",
    "outputId": "d0572e5d-044a-41f4-cddd-1b919d2089ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. Median House Value: 14.999\n",
      "Max. Median House Value: 500.001\n",
      "Difference between Min. and Max.: 485.002\n",
      "Root Mean Squared Error: 232.046\n"
     ]
    }
   ],
   "source": [
    "root_mean_squared_error = np.sqrt(epoch_valid_losses[-1])\n",
    "\n",
    "min_house_value = cali_df[\"median_house_value\"].min()\n",
    "max_house_value = cali_df[\"median_house_value\"].max()\n",
    "min_max_difference = max_house_value - min_house_value\n",
    "\n",
    "print(\"Min. Median House Value: %0.3f\" % min_house_value)\n",
    "print(\"Max. Median House Value: %0.3f\" % max_house_value)\n",
    "print(\"Difference between Min. and Max.: %0.3f\" % min_max_difference)\n",
    "print(\"Root Mean Squared Error: %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QU5sLyYTqzqL"
   },
   "source": [
    "#### Is There a Standard Heuristic for Model Tuning?\n",
    "\n",
    "This is a commonly asked question. The short answer is that the effects of different hyperparameters are data dependent. So there are no hard-and-fast rules; you'll need to test on your data.\n",
    "\n",
    "That said, here are a few rules of thumb that may help guide you:\n",
    "\n",
    " * Training error should steadily decrease, steeply at first, and should eventually plateau as training converges.\n",
    " * If the training has not converged, try running it for longer.\n",
    " * If the training error decreases too slowly, increasing the learning rate may help it decrease faster.\n",
    "   * But sometimes the exact opposite may happen if the learning rate is too high.\n",
    " * If the training error varies wildly, try decreasing the learning rate.\n",
    "   * Lower learning rate plus larger number of steps or larger batch size is often a good combination.\n",
    " * Very small batch sizes can also cause instability.  First try larger values like 100 or 1000, and decrease until you see degradation.\n",
    "\n",
    "Again, never go strictly by these rules of thumb, because the effects are data dependent.  Always experiment and verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vqb3_glKGc6"
   },
   "source": [
    "### Step 8: Convert to Static Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8sNtSeKKGc8"
   },
   "source": [
    "Eager Mode is on by default for Tensorflow 2.0 but we can also convert our models to static graph to enjoy the performance edge it offers after we completed the debugging in the more friendly Eager Mode by using the `@tf.function` decorator. This shrinks our time to run 10 epochs from 12 to 2 seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1chYBMDKGc9"
   },
   "outputs": [],
   "source": [
    "#datasets\n",
    "#shuffle with buffer equal to size of dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\\\n",
    "  .shuffle(buffer_size=train_y.shape[0]).batch(64)\n",
    "#no shuffling for validation\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\\\n",
    "  .batch(valid_y.shape[0])\n",
    "\n",
    "#architecture\n",
    "class MLP(Model):\n",
    "    def __init__(self,output_dims=[64,32,1]):\n",
    "        super(MLP,self).__init__()\n",
    "        #we can also use the predefined tf.keras.layers.Dense; we can also specify activations\n",
    "        self.linears = [layers.Dense(i,activation='relu') for i in output_dims]\n",
    "    def call(self,x):\n",
    "        for l in self.linears[:-1]: x = l(x)\n",
    "        return self.linears[-1](x)\n",
    "m = MLP([32,32,1])\n",
    "\n",
    "#loss fn\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 2e-3,\n",
    "                                    beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVGsICmRKGdA"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_batch(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = m(x) #prediction\n",
    "        train_loss = loss_fn(y,preds) #record loss\n",
    "        gradients = tape.gradient(train_loss,m.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients,m.trainable_weights))\n",
    "    return train_loss\n",
    "\n",
    "@tf.function\n",
    "def valid_batch(x,y):\n",
    "    preds = m(x) #prediction\n",
    "    valid_loss = loss_fn(y,preds) #record loss\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkXx6XpcKGdD",
    "outputId": "b4599706-182c-4782-f700-7f8263a719cc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function train_batch at 0x000001BF6D24B6A8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D24B6A8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function train_batch at 0x000001BF6D24B6A8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D24B6A8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D74B268> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D74B268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D74B268> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D74B268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function train_batch at 0x000001BF6D24B6A8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D24B6A8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function train_batch at 0x000001BF6D24B6A8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D24B6A8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function train_batch at 0x000001BF6D24B6A8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D24B6A8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function train_batch at 0x000001BF6D24B6A8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D24B6A8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function valid_batch at 0x000001BF6D24B730> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function valid_batch at 0x000001BF6D24B730>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function valid_batch at 0x000001BF6D24B730> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function valid_batch at 0x000001BF6D24B730>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MLP.call of <__main__.MLP object at 0x000001BF6D250390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "epoch 0 - Train Loss: 10508.275390625;          Valid Loss: 10913.00390625\n",
      "epoch 1 - Train Loss: 6264.015625;          Valid Loss: 6396.9130859375\n",
      "epoch 2 - Train Loss: 4866.18994140625;          Valid Loss: 4957.501953125\n",
      "epoch 3 - Train Loss: 4405.7265625;          Valid Loss: 4457.57177734375\n",
      "epoch 4 - Train Loss: 4291.26611328125;          Valid Loss: 4272.45361328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 - Train Loss: 4242.2001953125;          Valid Loss: 4181.041015625\n",
      "epoch 6 - Train Loss: 4235.90185546875;          Valid Loss: 4115.9208984375\n",
      "epoch 7 - Train Loss: 4220.62890625;          Valid Loss: 4055.507568359375\n",
      "epoch 8 - Train Loss: 4216.525390625;          Valid Loss: 3998.440673828125\n",
      "epoch 9 - Train Loss: 4211.4091796875;          Valid Loss: 3947.78759765625\n",
      "Done in 0:00:02.285801\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "#to log epoch-level train and validation losses\n",
    "epoch_train_losses = []\n",
    "epoch_valid_losses = []\n",
    "for e in range(10):\n",
    "    #training loop\n",
    "    for i,(x,y) in enumerate(train_ds):\n",
    "        epoch_train_loss = []\n",
    "        train_loss = train_batch(x,y)\n",
    "        epoch_train_loss.append(train_loss)\n",
    "    epoch_train_losses.append(np.mean(epoch_train_loss))\n",
    "    \n",
    "    #validation loop\n",
    "    for i,(x,y) in enumerate(valid_ds):\n",
    "        epoch_valid_loss = []\n",
    "        valid_loss = valid_batch(x,y)\n",
    "        epoch_valid_loss.append(valid_loss)\n",
    "        # do not record or apply gradients\n",
    "    epoch_valid_losses.append(np.mean(epoch_valid_loss))\n",
    "    \n",
    "    #log\n",
    "    print(f'epoch {e} - Train Loss: {np.mean(epoch_train_loss)};\\\n",
    "          Valid Loss: {np.mean(epoch_valid_loss)}')\n",
    "\n",
    "print(f'Done in {datetime.now()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGWLyJCGKGdI",
    "outputId": "7c12af2c-1540-485a-a88b-22670643a54d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf6d065da0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot losses by epoch\n",
    "plt.plot(epoch_train_losses)\n",
    "plt.plot(epoch_valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vqb3_glKGc6"
   },
   "source": [
    "### Homework : change to mish activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2.math as F\n",
    "#import torch\n",
    "#import torch.nn.functional as F\n",
    "# Now change to mish activation function\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\\\n",
    "  .shuffle(buffer_size=train_y.shape[0]).batch(64)\n",
    "#no shuffling for validation\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\\\n",
    "  .batch(valid_y.shape[0])\n",
    "\n",
    "#architecture\n",
    "class Mish(Model):\n",
    "    def __init__(self,output_dims=[64,32,1]):\n",
    "        super(Mish,self).__init__()\n",
    "        # use Activation = None and implement it by self\n",
    "        self.linears = [layers.Dense(i,activation=None) for i in output_dims]\n",
    "        \n",
    "    def call(self,x):\n",
    "        for l in self.linears[:-1]: \n",
    "            # implement activation function\n",
    "            x = l(x)\n",
    "            # every x will be in activation before go to the next step\n",
    "            x = x*tf.math.tanh(F.softplus(x))\n",
    "            #print(\"x = \",x)\n",
    "            #x = x * (torch.tanh(F.softplus(x)))\n",
    "        #print(\"answer = \",self.linears[-1](x).eval())\n",
    "        return self.linears[-1](x)\n",
    "    \n",
    "    \n",
    "    \n",
    "m = Mish([32,32,1])\n",
    "#loss fn\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 2e-3,\n",
    "                                    beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_batch(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = m(x) #prediction\n",
    "        train_loss = loss_fn(y,preds) #record loss\n",
    "        gradients = tape.gradient(train_loss,m.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients,m.trainable_weights))\n",
    "    return train_loss\n",
    "\n",
    "@tf.function\n",
    "def valid_batch(x,y):\n",
    "    preds = m(x) #prediction\n",
    "    valid_loss = loss_fn(y,preds) #record loss\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function train_batch at 0x000001BF6D74B378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D74B378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function train_batch at 0x000001BF6D74B378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D74B378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D26E488> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D26E488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D26E488> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001BF6D26E488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function train_batch at 0x000001BF6D74B378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D74B378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function train_batch at 0x000001BF6D74B378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D74B378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function train_batch at 0x000001BF6D74B378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D74B378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function train_batch at 0x000001BF6D74B378> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function train_batch at 0x000001BF6D74B378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function valid_batch at 0x000001BF6AA252F0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function valid_batch at 0x000001BF6AA252F0>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function valid_batch at 0x000001BF6AA252F0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function valid_batch at 0x000001BF6AA252F0>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Mish.call of <__main__.Mish object at 0x000001BF6E910860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "epoch 0 - Train Loss: 7716.73828125;          Valid Loss: 11426.4072265625\n",
      "epoch 1 - Train Loss: 5143.63671875;          Valid Loss: 6133.7392578125\n",
      "epoch 2 - Train Loss: 4207.16064453125;          Valid Loss: 4867.4091796875\n",
      "epoch 3 - Train Loss: 3813.5634765625;          Valid Loss: 4379.6611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 - Train Loss: 3601.888671875;          Valid Loss: 4163.35009765625\n",
      "epoch 5 - Train Loss: 3478.790283203125;          Valid Loss: 4028.227294921875\n",
      "epoch 6 - Train Loss: 3407.04345703125;          Valid Loss: 3927.816650390625\n",
      "epoch 7 - Train Loss: 3363.2216796875;          Valid Loss: 3843.898193359375\n",
      "epoch 8 - Train Loss: 3330.62255859375;          Valid Loss: 3775.611083984375\n",
      "epoch 9 - Train Loss: 3301.612548828125;          Valid Loss: 3718.466796875\n",
      "Done in 0:00:03.061004\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "#to log epoch-level train and validation losses\n",
    "epoch_train_losses = []\n",
    "epoch_valid_losses = []\n",
    "for e in range(10):\n",
    "    #training loop\n",
    "    for i,(x,y) in enumerate(train_ds):\n",
    "        epoch_train_loss = []\n",
    "        train_loss = train_batch(x,y)\n",
    "        epoch_train_loss.append(train_loss)\n",
    "    epoch_train_losses.append(np.mean(epoch_train_loss))\n",
    "    \n",
    "    #validation loop\n",
    "    for i,(x,y) in enumerate(valid_ds):\n",
    "        epoch_valid_loss = []\n",
    "        valid_loss = valid_batch(x,y)\n",
    "        epoch_valid_loss.append(valid_loss)\n",
    "        # do not record or apply gradients\n",
    "    epoch_valid_losses.append(np.mean(epoch_valid_loss))\n",
    "    \n",
    "    #log\n",
    "    print(f'epoch {e} - Train Loss: {np.mean(epoch_train_loss)};\\\n",
    "          Valid Loss: {np.mean(epoch_valid_loss)}')\n",
    "\n",
    "print(f'Done in {datetime.now()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf6e8bb160>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot losses by epoch\n",
    "plt.plot(epoch_train_losses)\n",
    "plt.plot(epoch_valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "JndnmDMp66FL",
    "ci1ISxxrZ7v0"
   ],
   "name": "first_steps_with_tensor_flow2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
